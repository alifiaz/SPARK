{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Accessing Data\n\nApache Spark&trade; and Databricks&reg; have numerous ways to access your data.\n\n## In this lesson you\n* Create a table from an existing file\n* Create a table by uploading a data file from your local machine\n* Mount an S3 bucket to DBFS\n* Create tables for Databricks data sets to use throughout the course\n\n## Audience\n* Primary Audience: Data Analysts\n* Additional Audiences: Data Engineers and Data Scientists\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 6.2**\n* Familiarity with <a href=\"https://www.w3schools.com/sql/\" target=\"_blank\">ANSI SQL</a> is required"],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the<br/>\nstart of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/nf81as9ya0?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/nf81as9ya0?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["### Create a table from an existing file\n\nDBFS (the <a href=\"https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">Databricks File System</a>) is the built-in, S3-backed, alternative to \nHDFS (the <a href=\"http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html\" target=\"_blank\">Hadoop Distributed File System</a>).\n\nCreating a table from an existing file in DBFS allows you to access the file as if it were a Spark table. It does **not** copy any data."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/ysgdonjuk6?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/ysgdonjuk6?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nThe example below creates a table from the **ip-geocode.parquet** file (if it doesn't exist).\n\nFor Parquet files, you need to specify only one option: the path to the file.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> A Parquet \"file\" is actually a collection of files stored in a single directory.  The Parquet format offers features making it the ideal choice for storing \"big data\" on distributed file systems. For more information, see <a href=\"https://parquet.apache.org/\" target=\"_blank\">Apache Parquet</a>.\n\nYou can create a table from an existing DBFS file with a simple SQL `CREATE TABLE` statement. If you don't select a database, the database called \"default\" is used. Here, we'll use a database called \"junk\", to remind us to delete these tables later."],"metadata":{}},{"cell_type":"code","source":["%sql\nCREATE DATABASE IF NOT EXISTS junk;\n\nUSE junk;\n\nCREATE TABLE IF NOT EXISTS IPGeocode\n  USING parquet\n  OPTIONS (\n    path \"dbfs:/mnt/training/ip-geocode.parquet\"\n  )"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["-sandbox\nNow the table has been defined. You can see it in Databricks.\n0. Click the **Data** icon on the left sidebar<br/>\n<div><img src=\"https://files.training.databricks.com/images/eLearning/data-tab.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px\"/></div>\n0. Select the database **junk**.\n0. Select the table **ipgeocode**.  \n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Right-click and open in a new tab, so you don't lose your place in this notebook\n<div><img src=\"https://files.training.databricks.com/images/eLearning/database.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px\"/></div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nYou see the schema of the table, along with a sample of its data.\n\n<img src=\"https://files.training.databricks.com/images/eLearning/db-table-example-1.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px\"/>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Using A Personal Database\n\nAny tables created or droped will be done so in the **`junk`** database.\n\nHowever, every user of this system, if running this same code, will be altering the same tables. \n\nIn cases such as this one, it is often better to use a \"personal\" database.\n\nFor this reason, we will switch back to your personal database now.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> We need to use the Spark programming API here only because we are unable to parameterize a **`%sql`** cell with the database we setup for you (as represtend by **`databaseName`**)."],"metadata":{}},{"cell_type":"code","source":["# Programatically exectue a similar SQL command as above\nspark.sql(f\"USE {databaseName}\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### File formats other than Parquet\n\nYou can also create a table from other file formats. \n\nOne common format is CSV (comma-separated-values) for which you can specify:\n* The file's delimiter, the default is \"**,**\"\n* Whether the file has a header or not, the default is **false**\n* Whether or not to infer the schema, the default is **false**"],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/brunhjed4t?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/brunhjed4t?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["In order to know which options to use, look at the first couple of lines of the file.\n\nTake a look at the head of the file **/mnt/training/bikeSharing/data-001/day.csv.**"],"metadata":{}},{"cell_type":"code","source":["%fs head /mnt/training/bikeSharing/data-001/day.csv --maxBytes=492"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["Spark can create a table from that CSV file, as well.\n\nAs you can see above:\n* There is a header\n* The file is comma separated (the default)\n* Let Spark infer what the schema is"],"metadata":{}},{"cell_type":"code","source":["%sql\nCREATE TABLE IF NOT EXISTS BikeSharingDay\n  USING csv\n  OPTIONS (\n    path \"/mnt/training/bikeSharing/data-001/day.csv\",\n    inferSchema \"true\",\n    header \"true\"\n  )"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Now the table is defined, view its contents with a simple select statement."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT * FROM BikeSharingDay"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["-sandbox\nNext, drop the table.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> This does not delete the file from which the table was created.  Rather, it simply removes the table definition from Spark."],"metadata":{}},{"cell_type":"code","source":["%sql\nDROP TABLE BikeSharingDay"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### Upload a local file as a table\n\nThe last two examples use files already loaded on the \"server.\"\n\nDatabricks also supports creating tables by uploading files. \n\nNext, download the following file to your local machine: <a href=\"https://s3-us-west-2.amazonaws.com/databricks-corp-training/common/dataframes/state-income.csv\">state-income.csv</a>"],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/anplj4runo?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/anplj4runo?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nSelect **Data** from the sidebar, and click on the **junk** database.\n\nThis time, select the **+** icon to create a new table.\n\n<img src=\"https://files.training.databricks.com/images/eLearning/create-table-1-junk-db.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px\"/>\n\nEnsure that **Upload File** is selected. Then, select the **state-income.csv** file from your machine, or drag-and-drop the file to initiate the upload.\n\n<img src=\"https://files.training.databricks.com/images/eLearning/create-table-2.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px\"/>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nOnce the file is uploaded, create the actual table:\n\n1. Click the **Create Table with UI** button  \n<img src=\"https://files.training.databricks.com/images/eLearning/create-table-3.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; margin: 20px\"/>\n2. In the drop-down dialog, select a cluster\n3. Click the **Preview Table** button \n<img src=\"https://files.training.databricks.com/images/eLearning/create-table-4.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; margin: 20px\"/>\n4. Another dialog will drop down. Choose the **junk** database\n5. Select the **First row is header** checkbox\n6. Click the **Create Table** button\n\n<img src=\"https://files.training.databricks.com/images/eLearning/create-table-5.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; margin-top: 20px\"/>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nOnce Databricks finishes processing the file, you'll see another table preview.\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Databricks tries to choose a table name that doesn't clash with tables created by other users. However, a name clash is still possible. If the table already exists, you'll see an error like the following:\n\n<img src=\"https://files.training.databricks.com/images/eLearning/create-table-6.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; margin-top: 20px; padding: 10px\"/>\n\nIf that happens, just type in a different table name, and try again."],"metadata":{}},{"cell_type":"markdown","source":["Next, drop the table to ensure other users don't have a name conflict when uploading their tables."],"metadata":{}},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS state_income"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### How to mount an S3 bucket to DBFS\n\nAmazon Web Services (AWS) provides cloud file storage in the form of the Amazon Simple Storage Service (S3).  Files are stored in \"buckets.\"\nIf you have an S3 account, you can create a bucket, store data files in that bucket, and mount the bucket as a DBFS directory. \n\nOnce the bucket is mounted as a DBFS directory, you can access it without exposing your S3 keys."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/yfd41f8du5?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/yfd41f8du5?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["Take a look at the buckets already mounted to your DBFS:"],"metadata":{}},{"cell_type":"code","source":["%fs mounts"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["-sandbox\nMount your own bucket to a new mount point. To do so, use the `dbutils.fs.mount(..)` function.\n\nBelow, mount a Databricks S3 bucket (using a read-only access and secret key pair), access one of the files in the bucket as a DBFS path, then unmount the bucket.\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> The mount point **must** start with `/mnt/`."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nCreate the mount point with `%fs mount`.\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> If the directory was already mounted, you would receive the following error:\n\n> Directory already mounted: /mnt/temp-training\n\nIn this case, use a different mount point such as `temp-training-2`, and ensure you update all three references below."],"metadata":{}},{"cell_type":"code","source":["%fs mount s3a://AKIAJBRYNXGHORDHZB4A:a0BzE1bSegfydr3%2FGE3LSPM6uIV5A4hOUfpH8aFF@databricks-corp-training/common /mnt/temp-training"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["List the contents of the directory you just mounted:"],"metadata":{}},{"cell_type":"code","source":["%fs ls /mnt/temp-training"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["Take a peek at the head of the file `auto-mpg.csv`:"],"metadata":{}},{"cell_type":"code","source":["%fs head /mnt/temp-training/auto-mpg.csv"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["Now you are done, unmount the directory."],"metadata":{}},{"cell_type":"code","source":["# %fs unmount /mnt/temp-training"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["Create your own access keys in AWS for your own S3 buckets and mount them the same way.\n\nThis allows access to your S3 data directly from Databricks distributed file system (DBFS).\n\nOnce mounted, you can delete the single cell that contained your keys or even the entire notebook protecting your keys from unscrupulous actors."],"metadata":{}},{"cell_type":"markdown","source":["## Summary\n\nDatabricks allows you to:\n  * Create tables from existing data\n  * Create tables from uploaded files\n  * Mount your own S3 buckets"],"metadata":{}},{"cell_type":"markdown","source":["## Review Questions\n**Q:** How can you see which tables have been created?    \n**A:** Go to the **Data** section using the button-bar to the left.\n\n**Q:** What is Amazon S3?  \n**A:** Amazon S3 stands for Simple Storage Service.  It provides cloud-optimized storage of large data files that easily scales with your storage needs.\n\n**Q:** What is DBFS?  \n**A:** DBFS stands for Databricks File System.  DBFS provides for the cloud what the Hadoop File System (HDFS) provides for local spark deployments.  DBFS uses Amazon S3 and makes it easy to access files by name.\n\n**Q:** Which is more efficient to query, a parquet file or a CSV file?  \n**A:** Parquet files are highly optimized binary formats for storing tables.  The overhead is less than required to parse a CSV file.  Parquet is the big data analogue to CSV as it is optimized, distributed, and more fault tolerant than CSV files.\n\n**Q:** How can you create a new table?  \n**A:** Create new tables by either:\n* Uploading a new file using the Data tab on the left.\n* Mounting an existing file from DBFS.\n\n**Q:** What is the SQL syntax for defining a table in Spark from an existing parquet file in DBFS?  \n**A:** ```CREATE TABLE IF NOT EXISTS IPGeocode\nUSING parquet\nOPTIONS (\n  path \"dbfs:/mnt/training/ip-geocode.parquet\"\n)```"],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Cleanup\""],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["## Next Steps\n\nStart the next lesson, [Querying JSON & Hierarchical Data with SQL]($./SSQL 05 - Querying JSON)."],"metadata":{}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n\n* <a href=\"https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">The Databricks DBFS File System</a>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"SSQL 04a - Accessing Data - Amazon S3","notebookId":3953685866790449},"nbformat":4,"nbformat_minor":0}
