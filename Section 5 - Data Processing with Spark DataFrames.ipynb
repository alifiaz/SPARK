{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning PySpark \n",
    "### Video series\n",
    "\n",
    "### Packt Publishing\n",
    "\n",
    "**Author**: Tomasz Drabas\n",
    "**Date**:   2018-02-01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Section 5: Data Processing with Spark DataFrames\n",
    "\n",
    "In this section we will look at processing data using Spark DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"create\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderDate: timestamp (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Rep: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Units: long (nullable = true)\n",
      " |-- UnitCost: double (nullable = true)\n",
      " |-- Total: double (nullable = true)\n",
      "\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2016-01-06 00:00:00|   East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|2017-03-02 00:00:00|Central| Kivell|Binder|   50|   19.99| 999.5|\n",
      "|2016-02-09 00:00:00|Central|Jardine|Pencil|   36|    4.99|179.64|\n",
      "|2016-02-26 00:00:00|Central|   Gill|   Pen|   27|   19.99|539.73|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "date_cols = ['OrderDate']\n",
    "df = pandas.read_excel('sample_data.xlsx', parse_dates=date_cols)\n",
    "sample_df_inferred= spark.createDataFrame(df)\n",
    "sample_df_inferred.printSchema()\n",
    "sample_df_inferred.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+------+-----+--------+------+\n",
      "|OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+---------+-------+-------+------+-----+--------+------+\n",
      "|     null|   East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|     null|Central| Kivell|Binder|   50|   19.99| 999.5|\n",
      "|     null|Central|Jardine|Pencil|   36|    4.99|179.64|\n",
      "|     null|Central|   Gill|   Pen|   27|   19.99|539.73|\n",
      "+---------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "sample_df_inferred = spark.read.csv(\n",
    "    'sample_data.csv'\n",
    "    , header=True\n",
    "    , inferSchema = True\n",
    ")\n",
    "\n",
    "sample_df_inferred = (\n",
    "    sample_df_inferred\n",
    "    .withColumn('OrderDate'\n",
    "                , f.to_date('OrderDate', 'MM/dd/yy')\n",
    "               )\n",
    ")\n",
    "\n",
    "sample_df_inferred.show(4)\n",
    "\n",
    "sample_df_inferred.select(to_date(sample_df_inferred.OrderDate).alias('new_date')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+--------+\n",
      "|    Rep|  Item|Units|UnitCost|\n",
      "+-------+------+-----+--------+\n",
      "|  Jones|Pencil|   95|    1.99|\n",
      "| Kivell|Binder|   50|   19.99|\n",
      "|Jardine|Pencil|   36|    4.99|\n",
      "|   Gill|   Pen|   27|   19.99|\n",
      "+-------+------+-----+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Select\n",
    "sample_df_inferred.select('Rep', 'Item', 'Units','UnitCost').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+--------+\n",
      "|    Rep|  Item|Units|UnitCost|\n",
      "+-------+------+-----+--------+\n",
      "|  Jones|Pencil|   95|    1.99|\n",
      "| Kivell|Binder|   50|   19.99|\n",
      "|Jardine|Pencil|   36|    4.99|\n",
      "|   Gill|   Pen|   27|   19.99|\n",
      "+-------+------+-----+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Drop\n",
    "sample_df_inferred.drop('OrderDate', 'Region', 'Total').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|               Date|Location|\n",
      "+-------------------+--------+\n",
      "|2016-01-06 00:00:00|    East|\n",
      "|2017-03-02 00:00:00| Central|\n",
      "|2016-02-09 00:00:00| Central|\n",
      "|2016-02-26 00:00:00| Central|\n",
      "+-------------------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Select\n",
    "sample_df_inferred.select(f.col('OrderDate').alias('Date'),\n",
    "                          f.col('Region').alias('Location')).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------+------+-----+--------+------+\n",
      "|               Date|Location|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+--------+-------+------+-----+--------+------+\n",
      "|2016-01-06 00:00:00|    East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|2017-03-02 00:00:00| Central| Kivell|Binder|   50|   19.99| 999.5|\n",
      "|2016-02-09 00:00:00| Central|Jardine|Pencil|   36|    4.99|179.64|\n",
      "|2016-02-26 00:00:00| Central|   Gill|   Pen|   27|   19.99|539.73|\n",
      "+-------------------+--------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using WithColumn Method\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .withColumnRenamed('OrderDate', 'Date')\n",
    "    .withColumnRenamed('Region', 'Location')\n",
    "    .show(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2016-01-06 00:00:00|   East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|2017-03-02 00:00:00|Central| Kivell|Binder|   50|    null|  null|\n",
      "|2016-02-09 00:00:00|Central|Jardine|Pencil|   36|    null|  null|\n",
      "|2016-02-26 00:00:00|Central|   Gill|   Pen|   27|   19.99|539.73|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_df_broken_rdd = (\n",
    "    sample_df_inferred\n",
    "    .rdd\n",
    "    .map(lambda row: \n",
    "         row[:5] + \n",
    "         ((None, None) if np.random.rand() < 0.2 else tuple(row[5:]))\n",
    "    )\n",
    ")\n",
    "\n",
    "sample_df_broken = (\n",
    "    spark\n",
    "    .createDataFrame(\n",
    "        sample_df_broken_rdd\n",
    "        , sample_df_inferred.columns\n",
    "    )\n",
    ")\n",
    "\n",
    "sample_df_broken.dropna(subset=['OrderDate']).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2016-01-06 00:00:00|   East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|2017-03-02 00:00:00|Central| Kivell|Binder|   50|   19.99| 999.5|\n",
      "|2016-02-09 00:00:00|Central|Jardine|Pencil|   36|    4.99|179.64|\n",
      "|2016-02-26 00:00:00|Central|   Gill|   Pen|   27|   19.99|539.73|\n",
      "|2016-03-15 00:00:00|   West|Sorvino|Pencil|   56|    2.99|167.44|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_broken.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+------------------+------------------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|          UnitCost|             Total|\n",
      "+-------------------+-------+-------+------+-----+------------------+------------------+\n",
      "|2016-01-06 00:00:00|   East|  Jones|Pencil|   95|              1.99|            189.05|\n",
      "|2017-03-02 00:00:00|Central| Kivell|Binder|   50|             19.99| 999.4999999999999|\n",
      "|2016-02-09 00:00:00|Central|Jardine|Pencil|   36|              4.99|179.64000000000001|\n",
      "|2016-02-26 00:00:00|Central|   Gill|   Pen|   27|22.593611111111116| 610.0275000000001|\n",
      "+-------------------+-------+-------+------+-----+------------------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_unitCost = (\n",
    "    sample_df_broken\n",
    "    .select('UnitCost')\n",
    "    .agg(\n",
    "        f.mean(f.col('UnitCost'))\n",
    "        .alias('UnitCost')\n",
    "    ).toPandas()\n",
    "    .to_dict('records')\n",
    ")\n",
    "\n",
    "sample_df_fixed = (\n",
    "    sample_df_broken\n",
    "    .fillna(*avg_unitCost)\n",
    "    .withColumn('Total', f.col('Units') * f.col('UnitCost'))\n",
    ")\n",
    "\n",
    "sample_df_fixed.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Item|\n",
      "+-------+\n",
      "|   Desk|\n",
      "| Binder|\n",
      "|    Pen|\n",
      "|Pen Set|\n",
      "| Pencil|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_inferred.select(\"Item\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2016-01-06 00:00:00|   East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|2016-02-09 00:00:00|Central|Jardine|Pencil|   36|    4.99|179.64|\n",
      "|2016-03-15 00:00:00|   West|Sorvino|Pencil|   56|    2.99|167.44|\n",
      "|2016-04-18 00:00:00|Central|Andrews|Pencil|   75|    1.99|149.25|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using where method\n",
    "sample_df_inferred.where('Item = \"Pencil\"').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2016-01-06 00:00:00|   East|  Jones|Pencil|   95|    1.99|189.05|\n",
      "|2016-02-09 00:00:00|Central|Jardine|Pencil|   36|    4.99|179.64|\n",
      "|2016-03-15 00:00:00|   West|Sorvino|Pencil|   56|    2.99|167.44|\n",
      "|2016-04-18 00:00:00|Central|Andrews|Pencil|   75|    1.99|149.25|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Filter Method\n",
    "sample_df_inferred.filter('Item = \"Pencil\"').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+----+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+----+-----+--------+------+\n",
      "|2016-02-26 00:00:00|Central|   Gill| Pen|   27|   19.99|539.73|\n",
      "|2016-09-01 00:00:00|Central|  Smith|Desk|    2|   125.0| 250.0|\n",
      "|2016-10-22 00:00:00|   East|  Jones| Pen|   64|    8.99|575.36|\n",
      "|2016-11-08 00:00:00|   East| Parent| Pen|   15|   19.99|299.85|\n",
      "|2017-04-27 00:00:00|   East| Howard| Pen|   96|    4.99|479.04|\n",
      "|2017-06-17 00:00:00|Central| Kivell|Desk|    5|   125.0| 625.0|\n",
      "|2017-08-24 00:00:00|   West|Sorvino|Desk|    3|   275.0| 825.0|\n",
      "|2017-09-27 00:00:00|   West|Sorvino| Pen|   76|    1.99|151.24|\n",
      "+-------------------+-------+-------+----+-----+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_inferred.where(f.col(\"Item\").isin({\"Desk\",\"Pen\"})).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating data in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+\n",
      "|     Rep| Region|count|\n",
      "+--------+-------+-----+\n",
      "|   Jones|   East|    8|\n",
      "|    Gill|Central|    5|\n",
      "| Jardine|Central|    5|\n",
      "| Andrews|Central|    4|\n",
      "|  Kivell|Central|    4|\n",
      "| Sorvino|   West|    4|\n",
      "|  Parent|   East|    3|\n",
      "|   Smith|Central|    3|\n",
      "|  Morgan|Central|    3|\n",
      "|Thompson|   West|    2|\n",
      "|  Howard|   East|    2|\n",
      "+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_inferred.groupby('Rep', 'Region').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+------------------+\n",
      "|   Item|UnitsTotal|GrandTotal| AvgPerTransaction|\n",
      "+-------+----------+----------+------------------+\n",
      "|   Desk|        10|    1700.0| 566.6666666666666|\n",
      "| Binder|       722|   9577.65|            638.51|\n",
      "|    Pen|       278|   2045.22|           409.044|\n",
      "|Pen Set|       395|   4169.87| 595.6957142857143|\n",
      "| Pencil|       716|   2135.14|164.24153846153845|\n",
      "+-------+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sample_df_inferred\n",
    "    .groupby('Item')\n",
    "    .agg(\n",
    "          f.sum('Units').alias('UnitsTotal')\n",
    "        , f.sum('Total').alias('GrandTotal')\n",
    "        , f.avg('Total').alias('AvgPerTransaction')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-----------------+\n",
      "|    Rep|UnitsTotal|GrandTotal|AvgPerTransaction|\n",
      "+-------+----------+----------+-----------------+\n",
      "| Kivell|       193|   3109.44|           777.36|\n",
      "| Parent|       170|    3102.3|           1034.1|\n",
      "|Jardine|       281|   2812.19|           562.44|\n",
      "|  Jones|       396|   2363.04|           295.38|\n",
      "|   Gill|       213|   1749.87|           349.97|\n",
      "+-------+----------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_inferred.groupby('Rep')\\\n",
    "     .agg(f.sum('Units').alias('UnitsTotal'),\n",
    "     f.round(f.sum('Total'),2).alias('GrandTotal'),\n",
    "     f.round(f.avg('Total'),2).alias('AvgPerTransaction')).\\\n",
    "     orderBy('GrandTotal',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sample_df_inferred.groupby('Rep','Item')\\\n",
    "     .agg(f.sum('Units').alias('UnitsTotal'),\n",
    "     f.round(f.sum('Total'),2).alias('GrandTotal'),\n",
    "     f.round(f.avg('Total'),2).alias('AvgPerTransaction')).\\\n",
    "     orderBy('GrandTotal',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep</th>\n",
       "      <th>Item</th>\n",
       "      <th>UnitsTotal</th>\n",
       "      <th>GrandTotal</th>\n",
       "      <th>AvgPerTransaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jardine</td>\n",
       "      <td>Binder</td>\n",
       "      <td>105</td>\n",
       "      <td>1933.95</td>\n",
       "      <td>966.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parent</td>\n",
       "      <td>Binder</td>\n",
       "      <td>81</td>\n",
       "      <td>1619.19</td>\n",
       "      <td>1619.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kivell</td>\n",
       "      <td>Pen Set</td>\n",
       "      <td>138</td>\n",
       "      <td>1484.94</td>\n",
       "      <td>742.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smith</td>\n",
       "      <td>Binder</td>\n",
       "      <td>87</td>\n",
       "      <td>1305.00</td>\n",
       "      <td>1305.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parent</td>\n",
       "      <td>Pen Set</td>\n",
       "      <td>74</td>\n",
       "      <td>1183.26</td>\n",
       "      <td>1183.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rep     Item  UnitsTotal  GrandTotal  AvgPerTransaction\n",
       "0  Jardine   Binder         105     1933.95             966.98\n",
       "1   Parent   Binder          81     1619.19            1619.19\n",
       "2   Kivell  Pen Set         138     1484.94             742.47\n",
       "3    Smith   Binder          87     1305.00            1305.00\n",
       "4   Parent  Pen Set          74     1183.26            1183.26"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.toPandas()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Data\n",
    "## .select(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|    Rep| Total|\n",
      "+-------+------+\n",
      "|  Jones|189.05|\n",
      "| Kivell| 999.5|\n",
      "|Jardine|179.64|\n",
      "|   Gill|539.73|\n",
      "|Sorvino|167.44|\n",
      "+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sample_df_inferred\n",
    "    .select('Rep','Total')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .sql(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_inferred.createOrReplaceTempView('sample_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+\n",
      "|          OrderDate|    Rep| Region| Total|\n",
      "+-------------------+-------+-------+------+\n",
      "|2016-04-18 00:00:00|Andrews|Central|149.25|\n",
      "|2017-04-10 00:00:00|Andrews|Central|131.34|\n",
      "|2017-10-30 00:00:00|Andrews|Central| 18.06|\n",
      "|2017-12-21 00:00:00|Andrews|Central|139.72|\n",
      "|2016-02-26 00:00:00|   Gill|Central|539.73|\n",
      "|2017-01-15 00:00:00|   Gill|Central|413.54|\n",
      "|2017-05-14 00:00:00|   Gill|Central| 68.37|\n",
      "|2017-05-30 00:00:00|   Gill|Central| 719.2|\n",
      "+-------------------+-------+-------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT OrderDate\n",
    "        , Rep\n",
    "        , Region\n",
    "        , Total\n",
    "    FROM sample_df_view\n",
    "    ORDER BY Rep\n",
    "        , OrderDate\n",
    "''').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|    Rep| Region|        GrandTotal|\n",
      "+-------+-------+------------------+\n",
      "| Kivell|Central|           3109.44|\n",
      "| Parent|   East|            3102.3|\n",
      "|Jardine|Central|           2812.19|\n",
      "|  Jones|   East|           2363.04|\n",
      "|   Gill|Central|1749.8700000000001|\n",
      "+-------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select Rep, Region, sum(Total) as GrandTotal\n",
    "FROM sample_df_view\n",
    "group by Rep, Region\n",
    "order by GrandTotal DESC\n",
    "''').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "commission = spark.createDataFrame(\n",
    "    sc.parallelize([\n",
    "          ('Central', 0.033)\n",
    "        , ('East',    0.032)\n",
    "        , ('West',    0.034)\n",
    "    ])\n",
    "    , ['Region', 'Commission']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+------+-----+--------+------+----------+\n",
      "| Region|          OrderDate|    Rep|  Item|Units|UnitCost| Total|Commission|\n",
      "+-------+-------------------+-------+------+-----+--------+------+----------+\n",
      "|Central|2017-03-02 00:00:00| Kivell|Binder|   50|   19.99| 999.5|     0.033|\n",
      "|Central|2016-02-09 00:00:00|Jardine|Pencil|   36|    4.99|179.64|     0.033|\n",
      "|Central|2016-02-26 00:00:00|   Gill|   Pen|   27|   19.99|539.73|     0.033|\n",
      "|Central|2016-04-18 00:00:00|Andrews|Pencil|   75|    1.99|149.25|     0.033|\n",
      "|Central|2016-05-05 00:00:00|Jardine|Pencil|   90|    4.99| 449.1|     0.033|\n",
      "|Central|2016-06-25 00:00:00| Morgan|Pencil|   90|    4.99| 449.1|     0.033|\n",
      "+-------+-------------------+-------+------+-----+--------+------+----------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_inferred.join(commission, on=['Region'], how='left_outer').show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+------+-----+--------+------+----------+---------------+\n",
      "| Region|          OrderDate|    Rep|  Item|Units|UnitCost| Total|Commission|CommissionValue|\n",
      "+-------+-------------------+-------+------+-----+--------+------+----------+---------------+\n",
      "|Central|2017-03-02 00:00:00| Kivell|Binder|   50|   19.99| 999.5|     0.033|           33.0|\n",
      "|Central|2016-02-09 00:00:00|Jardine|Pencil|   36|    4.99|179.64|     0.033|            6.0|\n",
      "|Central|2016-02-26 00:00:00|   Gill|   Pen|   27|   19.99|539.73|     0.033|           18.0|\n",
      "|Central|2016-04-18 00:00:00|Andrews|Pencil|   75|    1.99|149.25|     0.033|            5.0|\n",
      "+-------+-------------------+-------+------+-----+--------+------+----------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sample_df_inferred\n",
    "    .join(commission, on=['Region'], how='left_outer')\n",
    "    .withColumn('CommissionValue', f.round(f.col('Total') * f.col('Commission')))\n",
    "    .show(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| Region|    Rep|\n",
      "+-------+-------+\n",
      "|   East|  Jones|\n",
      "|Central| Kivell|\n",
      "|Central|Jardine|\n",
      "|Central|   Gill|\n",
      "+-------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Show\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .select('Region', 'Rep')\n",
    "    .show(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Region='East', Rep='Jones'),\n",
       " Row(Region='Central', Rep='Kivell'),\n",
       " Row(Region='Central', Rep='Jardine'),\n",
       " Row(Region='Central', Rep='Gill')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Take, RDD Method, row objects\n",
    "\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .select('Region', 'Rep')\n",
    "    .take(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2017-10-30 00:00:00|Central|Andrews|Pencil|   14|    1.29| 18.06|\n",
      "|2017-04-10 00:00:00|Central|Andrews|Pencil|   66|    1.99|131.34|\n",
      "|2016-04-18 00:00:00|Central|Andrews|Pencil|   75|    1.99|149.25|\n",
      "|2017-12-21 00:00:00|Central|Andrews|Binder|   28|    4.99|139.72|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Order by\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .orderBy('Rep', 'Region')\n",
    "    .show(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|          OrderDate| Region|    Rep|  Item|Units|UnitCost| Total|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "|2017-10-30 00:00:00|Central|Andrews|Pencil|   14|    1.29| 18.06|\n",
      "|2017-04-10 00:00:00|Central|Andrews|Pencil|   66|    1.99|131.34|\n",
      "|2016-04-18 00:00:00|Central|Andrews|Pencil|   75|    1.99|149.25|\n",
      "|2017-12-21 00:00:00|Central|Andrews|Binder|   28|    4.99|139.72|\n",
      "+-------------------+-------+-------+------+-----+--------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Sort\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .sort('Rep', 'Region')\n",
    "    .show(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved as Folder, Partition\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .csv('../data/sample_data_inferred.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sample_df_inferred\n",
    "    .write\n",
    "    .parquet(\n",
    "        '../data/sample_data_inferred.parquet'\n",
    "        , mode='overwrite'\n",
    "        , partitionBy='Rep'\n",
    "        , compression='gzip'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sample_df_inferred\n",
    "    .write\n",
    "    .json(\n",
    "        '../data/sample_data_inferred.json'\n",
    "        , mode='overwrite'\n",
    "        , dateFormat='yyyy-mm-dd'\n",
    "        , compression='gzip'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitfalls of using pure Python UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text][logo]\n",
    "\n",
    "[logo]: https://raw.githubusercontent.com/drabastomek/learningPySpark_video/master/common/images/udf.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCommission(value, commissionPercent):\n",
    "    return value * commissionPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+------+-----+--------+------+----------+---------------+\n",
      "| Region|          OrderDate|    Rep|  Item|Units|UnitCost| Total|Commission|CommissionValue|\n",
      "+-------+-------------------+-------+------+-----+--------+------+----------+---------------+\n",
      "|Central|2017-03-02 00:00:00| Kivell|Binder|   50|   19.99| 999.5|     0.033|        32.9835|\n",
      "|Central|2016-02-09 00:00:00|Jardine|Pencil|   36|    4.99|179.64|     0.033|        5.92812|\n",
      "|Central|2016-02-26 00:00:00|   Gill|   Pen|   27|   19.99|539.73|     0.033|       17.81109|\n",
      "|Central|2016-04-18 00:00:00|Andrews|Pencil|   75|    1.99|149.25|     0.033|        4.92525|\n",
      "+-------+-------------------+-------+------+-----+--------+------+----------+---------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "7.692247629165649\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "(\n",
    "    sample_df_inferred\n",
    "    .join(commission, on=['Region'], how='left_outer')\n",
    "    .withColumn('CommissionValue', calculateCommission(f.col('Total'), f.col('Commission')))\n",
    "    .show(4)\n",
    ")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "#SQLContext.registerFunction('comm',calculateCommission)\n",
    "#SQLContext.registerFunction(\"comm\", calculateCommission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repartitioning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using underlying RDD\n",
    "sample_df_inferred.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_repartitioned = sample_df_inferred.repartition(4, 'Rep')\n",
    "sample_df_repartitioned.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
